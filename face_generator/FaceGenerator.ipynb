{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data as Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/\"\n",
    "BATCH_SIZE = 64\n",
    "DATA_NAMES = [DATA_PATH + str(line).rstrip() for line in open(\"./100k.txt\",\"r\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data_names: list, batch_size: int):\n",
    "    \"\"\"\n",
    "        Grab a certain number of random images from the dataset\n",
    "        Parameters:\n",
    "            data_names: the list of names of images\n",
    "            batch_size: how many images to grab \n",
    "    \"\"\"\n",
    "    files = random.sample(data_names, batch_size)\n",
    "    batch = []\n",
    "    for file in files:\n",
    "        if random.choice([True, False]):\n",
    "            batch.append(np.asarray(Image.open(file).transpose(Image.FLIP_LEFT_RIGHT)))\n",
    "        else:\n",
    "            batch.append(np.asarray(Image.open(file)))                     \n",
    "    batch = np.asarray(batch)\n",
    "    normalized_batch = (batch / 127.5) - 1.0 # As you'd usually do\n",
    "    return normalized_batch, files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_z):\n",
    "    \"\"\"\n",
    "        logits is used to calculate loss\n",
    "        output is simply needed for the shape (which should theoretically be deriveable from from logits but that's beside the point)\n",
    "    \"\"\"\n",
    "    logits = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(3, 7, 1, activation='relu', input_shape=(256, 256, 3)),\n",
    "        tf.keras.layers.Conv2D(32, 5, (1, 2), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 5, 2, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 5, 2, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 3, 2, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, 2, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, 1, activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation=None),\n",
    "    ])\n",
    "    output = tf.sigmoid(logits)\n",
    "    # Notice how we don't really compile the model here, this is because we'll have to implement our own custom cost function\n",
    "    return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_z, output_channel_dim, training):\n",
    "    \"\"\"\n",
    "        Obviously, the deepfake generator\n",
    "        \n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
